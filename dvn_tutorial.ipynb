{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Value Networks tutorial\n",
    "## Overview\n",
    "This tutorial presents DVNs, an energy-based model for structured prediction.\n",
    "DVN learn a value function, i.e. they estimate the performance of a solution __y__, w.r.t the ground-truth __y∗__,\n",
    "as a function of the input __x__ and the solution __y__. I.e, the goal of training is to get a value network _v_ for which\n",
    "\n",
    "_v_(__x__, __y__; __θ__) = v∗ (__y__, __y∗__), (Eq. (5) in the paper)\n",
    "\n",
    "where v∗ is the true performance of __y__, given the ground truth __y∗__. In this example, we use F1 scores (Eq (7)  in the paper).\n",
    "Once the network is trained, as in this notebook, the network can predict the performance under absence of the ground truth __y∗__.\n",
    "\n",
    "Predictions are made by gradient ascent, w.r.t. __y__.\n",
    "Given some initial solution __y__, the network estimates the value of that solutions and then __y__ is updated, so that the estimated value increases.\n",
    "For more details, see the paper.\n",
    "\n",
    "__Paper:__ \tDeep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs\n",
    "M. Gygli, M. Norouzi, A. Angelova. ICML 2017 https://people.ee.ethz.ch/~gyglim/dvn/dvn_imcl17.pdf \n",
    "\n",
    "__Code by:__ Michael Gygli https://twitter.com/GygliMichael\n",
    "\n",
    "## Contents of this tutorial\n",
    "In this we use a DVN that was already trained on the Bibtex dataset and analyze it's predictions.\n",
    "In particular we look at what value the DVN assigns to the ground truth and how it iteratively makes predictions.\n",
    "\n",
    "## Prerequisites\n",
    "This code works with python 2.7.\n",
    "Addionally, the notebook needs jupyter. Consult http://jupyter.readthedocs.io/en/latest/install.html on how to install it.\n",
    "\n",
    "### Installing DVN\n",
    "Run\n",
    "```bash\n",
    "git clone git@github.com:gyglim/dvn.git\n",
    "cd dvn\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "then the notebook can be started with\n",
    " ```bash\n",
    " jupyter notebook\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bibtex_pretrained/weights-88148\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import mlc_datasets\n",
    "import value_nets\n",
    "import numpy as np\n",
    "\n",
    "# Create the model\n",
    "net = value_nets.ValueNetwork('/tmp/bibtex',\n",
    "                                  feature_dim=1836,\n",
    "                                  label_dim=159,\n",
    "                                  learning_rate=0.1, # the learning rate when estimating the DVN parameters\n",
    "                                  inf_lr=0.5, # the learning rate for the gradient ascent at inference\n",
    "                                  num_hidden=150, # number of hidden units\n",
    "                                  weight_decay=0.001,\n",
    "                                  include_second_layer=False)\n",
    "\n",
    "\n",
    "# Restore the pre-trained weights\n",
    "net.restore(\"./bibtex_pretrained/weights-88148\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test_labels, test_features, tagnames, txt_inputs = mlc_datasets.get_bibtex('test')\n",
    "\n",
    "# Normalize the test features\n",
    "normalized_test_features = np.array(test_features, np.float64)\n",
    "normalized_test_features -= net.mean\n",
    "normalized_test_features /= net.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing what the model learns\n",
    "The DVN learns to predict the performance of a labelling __y__.\n",
    "Thus, it is also possible to inspect the model and understand how it makes predictions.\n",
    "Let's look at one example and what performance the model estimates for the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input words: 0, 000, 02, 05, 06, 1, 10, 100, 11, 12, 13, 14, 15, 16, 17, 18, 1997, 1998, 1999, 2, 20, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 24, 25, 3, 30, 4, 40, 5, 50, 6, 60, 7, 8, 9, 95, 98, a, ab, ability, able, about, above, absence, abstract, academic, access, accessible, according, account, accuracy, accurate, achieve, achieved, acid, acids, acm, acquisition, across, act, action, activation, active, activities, activity, actual, adaptation, adapted, adaptive, added, addition, additional, address, addressed, addresses, advanced, advances, advantage, advantages, affect, affected, affinity, after, against, age, agent, agents, agreement, aim, aims, al, algorithm, algorithms, all, allow, allowed, allowing, allows, almost, along, alpha, already, als, also, alternative, although, always, am, american, amino, among, amount, amounts, amperometric, an, analyse, analyses, analysis, analytical, analyze, analyzed, analyzing, and, annotation, annual, another, answer, anti, antibodies, antibody, antigen, any, apo, apob, apolipoprotein, apparent, appear, appears, applicable, application, applications, applied, apply, applying, approach, approaches, appropriate, approximate, approximately, approximation, aqueous, arbitrary, architecture, architectures, are, area, areas, argue, argued, arguments, arise, around, art, article, articles, artificial, as, aspect, aspects, assay, assays, assess, assessed, assessment, associated, association, assumption, assumptions, at, atomic, atoms, attempt, attention, attractive, auch, auf, author, authors, automated, automatic, automatically, automation, availability, available, average, aware, b, back, background, barrier, base, based, bases, basic, basis, be, because, become, becomes, been, before, begin, behavior, behavioral, behaviors, behaviour, being, believe, below, benefit, benefits, ber, best, beta, betta, better, between, beyond, binding, bioinformatics, biol, biological, biology, body, boltzmann, bond, book, both, bound, boundary, brain, brief, briefly, broad, build, building, built, bulk, business, but, by, c, calculate, calculated, calculation, calculations, call, called, can, cannot, capabilities, capable, capacity, capture, carbon, care, carlo, carried, case, cases, catalytic, categories, cause, caused, cell, cells, center, central, century, certain, chain, chains, challenge, challenges, change, changes, changing, character, characteristic, characteristics, characterization, characterize, characterized, charge, charged, chem, chemical, chemistry, child, children, choice, cholesterol, chosen, class, classes, classical, classification, clear, clearly, clin, clinical, close, cluster, clustering, clusters, co, code, coefficient, coefficients, cognitive, collaboration, collaborative, collected, collection, combination, combined, combines, combining, commercial, common, commonly, communication, communications, communities, community, comparable, comparative, compare, compared, comparing, comparison, competition, competitive, complete, completely, complex, complexes, complexity, component, components, composed, composition, compounds, comprehensive, computation, computational, computed, computer, computers, computing, concentration, concentrations, concept, concepts, conceptual, concerning, concerns, conclude, conclusion, conclusions, condition, conditions, conducted, conf, conference, configuration, confirmed, connected, connection, connections, consequence, consequences, consider, considerable, considered, considering, consistent, consisting, consists, constant, constants, constraints, construct, constructed, construction, consumption, contact, contain, contained, containing, contains, content, context, contexts, continuous, contrast, contribute, contribution, contributions, control, controlled, conventional, cooperative, core, correct, correlated, correlation, correlations, corresponding, cortex, cost, could, coupled, coupling, course, create, created, creating, creation, criteria, critical, cross, crucial, crystal, cultural, culture, current, currently, curves, cycle, d, daily, das, data, database, databases, date, day, de, deal, decision, decisions, decrease, decreased, define, defined, defining, definition, degree, degrees, dem, demonstrate, demonstrated, demonstrates, den, density, depend, dependence, dependent, depending, depends, der, derive, derived, des, describe, described, describes, describing, description, descriptions, design, designed, designing, despite, detail, detailed, details, detect, detected, detection, determination, determine, determined, determining, develop, developed, developers, developing, development, developmental, developments, device, devices, dft, diagram, did, die, differ, difference, differences, different, differential, difficult, diffusion, digital, dimension, dimensional, dimensions, direct, directed, direction, directions, directly, discovery, discrete, discuss, discussed, discusses, discussion, disease, disorder, display, distance, distinct, distributed, distribution, distributions, diverse, dna, do, document, documents, does, domain, domains, done, double, down, driven, due, during, dynamic, dynamical, dynamics, e, each, earlier, early, easily, easy, economic, education, educational, effect, effective, effectively, effectiveness, effects, efficiency, efficient, efficiently, effort, efforts, ein, eine, einer, either, electrochemical, electrode, electron, electronic, electrostatic, elements, embedded, emergence, emerging, emphasis, empirical, employed, en, enable, enables, enabling, end, energies, energy, engine, engineering, enhance, enhanced, enough, entire, entities, entropy, environment, environments, enzyme, enzymes, equal, equation, equations, equilibrium, equivalent, er, error, errors, es, especially, essential, establish, established, estimate, estimated, estimates, estimation, et, etc, european, evaluate, evaluated, evaluating, evaluation, even, event, events, every, evidence, evolution, evolutionary, evolving, exact, examine, examined, examines, example, examples, excellent, exchange, execution, exhibit, exhibits, exist, existence, existing, exists, expansion, expected, experience, experiences, experiment, experimental, experimentally, experiments, explain, explained, explanation, explicit, explicitly, exploration, explore, explored, explores, exploring, exponent, exponents, expressed, expression, extend, extended, extension, extensive, extent, external, extraction, f, face, facilitate, fact, factor, factors, family, far, fast, faster, feature, features, feedback, few, field, fields, fighting, final, finally, financial, find, finding, findings, finite, first, fish, fit, five, fixed, flexibility, flexible, flow, fluctuations, fluid, fock, focus, focused, focuses, focusing, follow, followed, following, follows, for, force, forces, form, formal, format, formation, formed, forms, found, foundation, four, fraction, fragments, framework, free, frequencies, frequency, frequently, from, full, fully, function, functional, functionality, functions, fundamental, further, furthermore, future, g, game, games, gap, gas, gaussian, gene, general, generalized, generally, generate, generated, generating, generation, generic, genes, genetic, genome, geometry, give, given, gives, glass, global, glucose, go, goal, goals, good, gradient, graph, graphical, graphs, great, greater, ground, group, groups, growing, growth, guide, h, had, half, hand, hard, hartree, has, have, having, he, health, help, hence, here, heterogeneous, hierarchical, high, higher, highly, his, historical, history, homogeneous, how, however, http, human, hybrid, hydrogen, hypermedia, hypothesis, i, idea, ideas, identical, identification, identified, identify, identifying, identity, ieee, if, ii, iii, illustrate, illustrated, im, image, images, imaging, immobilized, immunoassay, impact, implement, implementation, implemented, implications, importance, important, improve, improved, improvement, improvements, improving, in, include, included, includes, including, increase, increased, increases, increasing, increasingly, indeed, independent, index, indexing, indicate, indicated, indicates, indicating, individual, individuals, induced, industrial, industry, infinite, influence, information, infrastructure, initial, initio, innovation, input, insight, insights, instance, instead, institute, int, integrate, integrated, integrating, integration, intelligence, intelligent, intended, interact, interacting, interaction, interactions, interactive, interest, interesting, interface, interfaces, intermediate, internal, international, internet, interpretation, into, intrinsic, introduce, introduced, introduces, introduction, investigate, investigated, investigation, involved, involves, involving, ion, ions, is, isolated, issue, issues, ist, it, items, its, itself, iupap, j, joint, journal, just, k, key, kind, kinds, kinetic, kinetics, know, knowledge, known, l, la, labeled, lack, language, languages, large, largely, larger, last, latent, later, latter, lattice, law, laws, layer, ldl, lead, leading, leads, learn, learned, learning, least, led, left, length, less, lett, letters, level, levels, libraries, library, life, light, like, likely, limit, limitations, limited, limits, line, linear, link, linked, links, lipid, lipoprotein, lipoproteins, liquid, list, literature, little, local, located, location, logic, long, longer, look, loss, low, lower, m, machine, made, magnetic, magnitude, main, mainly, maintaining, maintenance, major, make, makes, making, male, management, managing, manner, many, map, mapping, maps, market, markets, mass, matching, material, materials, mathematical, mathematics, matrix, matter, maximum, may, mean, meaning, meaningful, means, measure, measured, measurement, measurements, measures, measuring, mechanical, mechanics, mechanism, mechanisms, media, mediated, medical, medium, members, membrane, memory, metadata, method, methodology, methods, metrics, might, min, minimal, minimum, mining, mit, mixed, mixture, ml, mm, mobile, mobility, mode, model, modeled, modeling, modelling, models, modern, modes, modification, modified, mol, molecular, molecule, molecules, monitoring, monoclonal, monte, more, moreover, most, motion, motivation, movement, much, multi, multimedia, multiple, must, n, namely, national, natural, nature, navigation, near, necessary, need, needed, needs, negative, network, networks, neural, new, next, nicht, no, nodes, noise, non, nonlinear, normal, not, notes, notion, novel, now, number, numbers, numerical, numerically, numerous, o, object, objective, objects, observation, observations, observe, observed, obtain, obtained, occur, occurs, of, off, offer, offers, often, old, on, once, one, ones, online, only, onto, ontologies, ontology, open, operations, opportunities, optimal, optimization, optimized, or, order, organization, organizational, organizations, organized, orientation, oriented, origin, original, other, others, our, out, outcomes, output, outside, over, overall, overview, own, oxidation, p, pages, pair, pairs, paper, papers, paradigm, parallel, parameter, parameters, part, partial, participants, particle, particles, particular, particularly, parts, past, path, pathway, patients, pattern, patterns, people, peptide, per, perform, performance, performed, period, periodic, personal, perspective, perspectives, perturbation, ph, phase, phases, phenomena, phenomenon, phys, physical, physics, place, planning, plasma, platform, play, point, points, policy, political, polymer, poor, popular, population, position, positive, possibility, possible, post, potential, potentials, power, powerful, practical, practice, practices, pre, precise, precision, predict, predicted, prediction, predictions, preliminary, presence, present, presentation, presented, presents, pressure, previous, previously, primarily, primary, principle, principles, prior, probabilistic, probability, problem, problems, proc, procedure, procedures, proceedings, process, processes, processing, produce, produced, produces, product, production, products, profile, profiles, program, programming, programs, progress, project, projects, promising, properties, property, propose, proposed, proposes, protein, proteins, protocol, prototype, prove, provide, provided, provides, providing, psychology, public, published, purpose, q, qm, qualitative, quality, quantitative, quantities, quantum, queries, query, question, questions, quite, r, random, range, ranging, rapid, rapidly, rate, rates, rather, ratio, rdf, re, reaction, reactions, reading, real, realistic, reason, reasoning, recent, recently, receptor, recognition, recognized, record, reduce, reduced, reducing, reduction, reference, references, regarding, regime, region, regions, related, relation, relations, relationship, relationships, relative, relatively, relaxation, relevance, relevant, reliability, reliable, remains, report, reported, reports, represent, representation, representations, represented, representing, represents, require, required, requirements, requires, res, research, researchers, reserved, residues, resolution, resonance, resource, resources, respect, respectively, response, responses, restricted, result, resulted, resulting, results, retrieval, reuse, rev, reveal, revealed, reveals, reverse, review, reviewed, reviews, rich, right, rights, rise, risk, robust, role, roles, rule, rules, run, s, same, sample, samples, scale, scales, scaling, scenario, scheme, school, sci, science, sciences, scientific, search, second, secondary, section, see, seem, seems, seen, selected, selection, self, semantic, semantics, semi, sense, sensitive, sensitivity, sensor, separate, separation, sequence, sequences, series, serum, serve, service, services, set, sets, setting, settings, seven, several, shape, share, shared, sharing, shift, short, should, show, showed, showing, shown, shows, siamese, sich, side, signal, significant, significantly, similar, similarity, simple, simulated, simulation, simulations, simultaneously, since, sind, single, site, sites, situation, situations, six, size, sizes, skills, slow, small, smaller, so, social, society, software, solid, solution, solutions, solve, solved, solvent, solving, some, source, sources, space, spatial, special, species, specific, specifically, specification, specificity, spectrum, speed, spin, splendens, square, ss, stability, stable, stages, standard, standards, starting, state, states, static, stationary, statistical, statistics, status, step, steps, still, stochastic, storage, strategies, strategy, strength, strong, strongly, structural, structure, structured, structures, students, studied, studies, study, studying, subject, subjects, subsequent, substrate, success, successful, successfully, such, sufficient, sufficiently, suggest, suggested, suggesting, suggests, suitable, support, supported, supporting, supports, surface, surfaces, survey, symmetry, symposium, synthesis, system, systematic, systems, t, tagging, take, taken, takes, taking, target, task, tasks, teachers, teaching, technical, technique, techniques, technological, technologies, technology, temperature, temperatures, temporal, term, terms, test, tested, testing, tests, text, than, that, the, their, them, themselves, then, theoretical, theoretically, theories, theory, there, therefore, thermal, thermodynamic, these, they, third, this, those, though, thought, three, through, throughout, thus, time, times, to, today, together, too, tool, tools, top, topic, topics, topology, total, toward, towards, traditional, training, trans, transactions, transfer, transformation, transition, transitions, transport, treated, treatment, trends, true, turn, two, type, types, typical, typically, u, und, under, underlying, understand, understanding, understood, unified, uniform, unique, unit, united, universal, university, up, upon, us, usage, use, used, useful, user, users, uses, using, usually, utility, v, validity, value, values, variable, variables, variation, variations, variety, various, varying, vector, velocity, version, versus, very, via, video, view, views, virtual, vision, visual, visualization, volume, von, vs, w, was, water, wave, way, ways, we, weak, web, weight, well, werden, were, what, when, where, whereas, whether, which, while, who, whole, whose, why, wide, widely, wie, will, wird, with, within, without, word, words, work, working, works, workshop, world, would, written, www, x, xml, xxiii, y, year, years, yet, yield, yields, you, young, z, zero, zu, zur\n"
     ]
    }
   ],
   "source": [
    "# Lets pick some example, e.g. a specific or a random one\n",
    "test_idx = 7 # np.random.randint(len(test_labels))\n",
    "\n",
    "# Print the input words for this example\n",
    "# The network uses a Bag of Words representation of these words as input\n",
    "print \"Input words: %s\" % \", \".join(txt_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see what performance DVN estimates for the ground truth labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print estimated value of true tags TAG_children, TAG_education, TAG_mathematics: 0.868; True score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Compute the estimated value\n",
    "estimated_value = net.sess.run(net.predicted_values, feed_dict={net.features_pl: normalized_test_features[test_idx].reshape(1,-1),\n",
    "                                       net.labels_pl: test_labels[test_idx].reshape(1,-1)})\n",
    "print \"Print estimated value of true tags %s: %.3f; True score: 1.0\" % (\", \".join(np.array(tagnames)[test_labels[test_idx]==1]),\n",
    "                                                  estimated_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now investigate how the model thinks it can improve the current labelling, by running inference with a labelling initiallized by the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted tags: TAG_children, TAG_education, TAG_kaldesignresearch, TAG_mathematics. Estimated score 0.868; True score 0.857\n"
     ]
    }
   ],
   "source": [
    "predicted_scores = net.inference(normalized_test_features[test_idx].reshape(1,-1),\n",
    "                                 initial_labels=test_labels[test_idx].reshape(1,-1).astype(np.float),\n",
    "                                 learning_rate=net.inf_lr).flatten()\n",
    "# Binarize the predictions\n",
    "predicted_labels = predicted_scores >= 0.5\n",
    "true_value = net.gt_value(predicted_labels, test_labels[test_idx])\n",
    "\n",
    "print \"Predicted tags: %s. Estimated score %.3f; True score %.3f\" % (\", \".join(np.array(tagnames)[predicted_labels==True]),\n",
    "                                                                     estimated_value,\n",
    "                                                                     true_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see (for test_idx = 7), the labelling changes a little bit. However, for most examples, it stays the same, indicating that the DVN is accurate in estimation the performance in the proximity of the ground truth.\n",
    "\n",
    "### We can also see what the model thinks are the most probable tags by running standard inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted tags: TAG_children, TAG_kaldesignresearch, TAG_mathematics. Estimated score 0.936; True score 0.667\n"
     ]
    }
   ],
   "source": [
    "# Run the iterative prediction on this test example\n",
    "predicted_labels = net.predict(normalized_test_features[test_idx], num_iterations=20)\n",
    "\n",
    "# Get the value the value net assigns to these labels\n",
    "estimated_value = net.sess.run(net.predicted_values, feed_dict={net.features_pl: normalized_test_features[test_idx].reshape(1,-1),\n",
    "                                       net.labels_pl: predicted_labels.reshape(1,-1)})\n",
    "\n",
    "# Compute the true performance\n",
    "true_value = net.gt_value(predicted_labels, test_labels[test_idx])\n",
    "\n",
    "print \"Predicted tags: %s. Estimated score %.3f; True score %.3f\" % (\", \".join(np.array(tagnames)[predicted_labels==True]),\n",
    "                                                                     estimated_value,\n",
    "                                                                     true_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's up to you to explore. What happens when you change the number of iterations? How does the initialization affect the final result?\n",
    "E.g. we initialized with __y__= 0, i.e. all labels get a zero probability. Is the network affected by setting the intial probability to one or to random values? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "While we used a pre-trained net here, you can also train them yourself, on your own structure prediction task.\n",
    "For more info see: https://github.com/gyglim/dvn and https://github.com/gyglim/dvn/blob/master/reproduce_results.py\n",
    "\n",
    "### For reference, let's also evaluate the model on the test dataset of bibtex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.857 (0 of 2515)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.413 (100 of 2515)\n",
      "0.415 (200 of 2515)\n",
      "0.427 (300 of 2515)\n",
      "0.432 (400 of 2515)\n",
      "0.437 (500 of 2515)\n",
      "0.435 (600 of 2515)\n",
      "0.442 (700 of 2515)\n",
      "0.442 (800 of 2515)\n",
      "0.440 (900 of 2515)\n",
      "0.439 (1000 of 2515)\n",
      "0.449 (1100 of 2515)\n",
      "0.449 (1200 of 2515)\n",
      "0.447 (1300 of 2515)\n",
      "0.448 (1400 of 2515)\n",
      "0.448 (1500 of 2515)\n",
      "0.448 (1600 of 2515)\n",
      "0.447 (1700 of 2515)\n",
      "0.448 (1800 of 2515)\n",
      "0.450 (1900 of 2515)\n",
      "0.447 (2000 of 2515)\n",
      "0.445 (2100 of 2515)\n",
      "0.444 (2200 of 2515)\n",
      "0.444 (2300 of 2515)\n",
      "0.446 (2400 of 2515)\n",
      "0.447 (2500 of 2515)\n",
      "0.447\n",
      "F1 score: 0.447\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model\n",
    "print \"F1 score: %.3f\" % mlc_datasets.evaluate_f1(net.predict, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
